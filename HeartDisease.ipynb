{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ca137535",
      "metadata": {
        "id": "ca137535"
      },
      "source": [
        "## Heart Disease Prediction Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4b43766a-5b7e-47e3-80c3-b4927bee2e94",
      "metadata": {
        "id": "4b43766a-5b7e-47e3-80c3-b4927bee2e94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e3a755-2b28-4f34-9e39-88e8abf2da88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Head of the dataset:\n",
            "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
            "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
            "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
            "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
            "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
            "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
            "\n",
            "   caa  thall  output  \n",
            "0    0      1       1  \n",
            "1    0      2       1  \n",
            "2    0      2       1  \n",
            "3    0      2       1  \n",
            "4    0      2       1  \n",
            "\n",
            "Missing values:\n",
            " age         0\n",
            "sex         0\n",
            "cp          0\n",
            "trtbps      0\n",
            "chol        0\n",
            "fbs         0\n",
            "restecg     0\n",
            "thalachh    0\n",
            "exng        0\n",
            "oldpeak     0\n",
            "slp         0\n",
            "caa         0\n",
            "thall       0\n",
            "output      0\n",
            "dtype: int64\n",
            "\n",
            "Descriptive statistics:\n",
            "               age         sex          cp      trtbps        chol         fbs  \\\n",
            "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
            "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
            "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
            "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
            "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
            "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
            "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
            "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
            "\n",
            "          restecg    thalachh        exng     oldpeak         slp         caa  \\\n",
            "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
            "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
            "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
            "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
            "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
            "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
            "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
            "\n",
            "            thall      output  \n",
            "count  303.000000  303.000000  \n",
            "mean     2.313531    0.544554  \n",
            "std      0.612277    0.498835  \n",
            "min      0.000000    0.000000  \n",
            "25%      2.000000    0.000000  \n",
            "50%      2.000000    1.000000  \n",
            "75%      3.000000    1.000000  \n",
            "max      3.000000    1.000000  \n",
            "\n",
            "Target variable distribution:\n",
            " output\n",
            "1    165\n",
            "0    138\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Head of the scaled dataset:\n",
            "        age  sex  cp    trtbps      chol  fbs  restecg  thalachh  exng  \\\n",
            "0  0.952197    1   3  0.763956 -0.256334    1        0  0.015443     0   \n",
            "1 -1.915313    1   2 -0.092738  0.072199    0        1  1.633471     0   \n",
            "2 -1.474158    0   1 -0.092738 -0.816773    0        0  0.977514     0   \n",
            "3  0.180175    1   1 -0.663867 -0.198357    0        1  1.239897     0   \n",
            "4  0.290464    0   0 -0.663867  2.082050    0        1  0.583939     1   \n",
            "\n",
            "    oldpeak  slp  caa  thall  output  \n",
            "0  1.087338    0    0      1       1  \n",
            "1  2.122573    0    0      2       1  \n",
            "2  0.310912    2    0      2       1  \n",
            "3 -0.206705    2    0      2       1  \n",
            "4 -0.379244    2    0      2       1  \n",
            "\n",
            "Shape of X_train before SMOTE: (212, 13)\n",
            "Shape of X_train after SMOTE: (230, 13)\n",
            "Shape of y_train before SMOTE: (212,)\n",
            "Shape of y_train after SMOTE: (230,)\n",
            "\n",
            "Gaussian Naive Bayes Model:\n",
            "Accuracy: 0.8132\n",
            "Precision: 0.8667\n",
            "Recall: 0.7800\n",
            "F1 Score: 0.8211\n",
            "Confusion Matrix:\n",
            "[[35  6]\n",
            " [11 39]]\n",
            "ROC AUC Score: 0.8829\n",
            "\n",
            "Support Vector Machine Model:\n",
            "Accuracy: 0.8132\n",
            "Precision: 0.8235\n",
            "Recall: 0.8400\n",
            "F1 Score: 0.8317\n",
            "Confusion Matrix:\n",
            "[[32  9]\n",
            " [ 8 42]]\n",
            "ROC AUC Score: 0.8739\n",
            "\n",
            "Random Forest Model:\n",
            "Accuracy: 0.7912\n",
            "Precision: 0.8163\n",
            "Recall: 0.8000\n",
            "F1 Score: 0.8081\n",
            "Confusion Matrix:\n",
            "[[32  9]\n",
            " [10 40]]\n",
            "ROC AUC Score: 0.9154\n",
            "\n",
            "Gradient Boosting Model:\n",
            "Accuracy: 0.7802\n",
            "Precision: 0.8409\n",
            "Recall: 0.7400\n",
            "F1 Score: 0.7872\n",
            "Confusion Matrix:\n",
            "[[34  7]\n",
            " [13 37]]\n",
            "ROC AUC Score: 0.8795\n",
            "\n",
            "Logistic Regression Model:\n",
            "Accuracy: 0.8132\n",
            "Precision: 0.8367\n",
            "Recall: 0.8200\n",
            "F1 Score: 0.8283\n",
            "Confusion Matrix:\n",
            "[[33  8]\n",
            " [ 9 41]]\n",
            "ROC AUC Score: 0.8854\n",
            "\n",
            "K-Nearest Neighbors Model:\n",
            "Accuracy: 0.8022\n",
            "Precision: 0.8478\n",
            "Recall: 0.7800\n",
            "F1 Score: 0.8125\n",
            "Confusion Matrix:\n",
            "[[34  7]\n",
            " [11 39]]\n",
            "ROC AUC Score: 0.8571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Neural Network (MLPClassifier) Model:\n",
            "Accuracy: 0.8132\n",
            "Precision: 0.8367\n",
            "Recall: 0.8200\n",
            "F1 Score: 0.8283\n",
            "Confusion Matrix:\n",
            "[[33  8]\n",
            " [ 9 41]]\n",
            "ROC AUC Score: 0.8761\n",
            "\n",
            "Best parameters for Random Forest: {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "\n",
            "Tuned Random Forest Model:\n",
            "Accuracy: 0.8132\n",
            "Precision: 0.8235\n",
            "Recall: 0.8400\n",
            "F1 Score: 0.8317\n",
            "Confusion Matrix:\n",
            "[[32  9]\n",
            " [ 8 42]]\n",
            "ROC AUC Score: 0.9146\n",
            "\n",
            "Best parameters for Gradient Boosting: {'learning_rate': 0.2, 'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "\n",
            "Tuned Gradient Boosting Model:\n",
            "Accuracy: 0.7912\n",
            "Precision: 0.8444\n",
            "Recall: 0.7600\n",
            "F1 Score: 0.8000\n",
            "Confusion Matrix:\n",
            "[[34  7]\n",
            " [12 38]]\n",
            "ROC AUC Score: 0.8815\n",
            "\n",
            "Best parameters for Logistic Regression: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "\n",
            "Tuned Logistic Regression Model:\n",
            "Accuracy: 0.8022\n",
            "Precision: 0.8333\n",
            "Recall: 0.8000\n",
            "F1 Score: 0.8163\n",
            "Confusion Matrix:\n",
            "[[33  8]\n",
            " [10 40]]\n",
            "ROC AUC Score: 0.8859\n",
            "\n",
            "Ensemble Model (VotingClassifier):\n",
            "Accuracy: 0.8352\n",
            "Precision: 0.8571\n",
            "Recall: 0.8400\n",
            "F1 Score: 0.8485\n",
            "Confusion Matrix:\n",
            "[[34  7]\n",
            " [ 8 42]]\n",
            "ROC AUC Score: 0.8990\n"
          ]
        }
      ],
      "source": [
        "## Heart Disease Prediction Model.\n",
        "# Importing necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('heart.csv') # Ensure the dataset is in the same directory or specify the correct path\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(\"Head of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Data preprocessing\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values:\\n\", data.isnull().sum())\n",
        "\n",
        "# Descriptive statistics\n",
        "print(\"\\nDescriptive statistics:\\n\", data.describe())\n",
        "\n",
        "# Check the balance of the target variable\n",
        "print(\"\\nTarget variable distribution:\\n\", data['output'].value_counts())\n",
        "\n",
        "# Feature scaling\n",
        "\n",
        "numerical_features = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
        "\n",
        "print(\"\\nHead of the scaled dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Split data into training and testing sets\n",
        "\n",
        "X = data.drop('output', axis=1)\n",
        "y = data['output']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Address class imbalance using SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nShape of X_train before SMOTE:\", X_train.shape)\n",
        "print(\"Shape of X_train after SMOTE:\", X_train_resampled.shape)\n",
        "print(\"Shape of y_train before SMOTE:\", y_train.shape)\n",
        "print(\"Shape of y_train after SMOTE:\", y_train_resampled.shape)\n",
        "\n",
        "# Model training and evaluation\n",
        "\n",
        "# Define a function to train and evaluate models\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "    return accuracy, precision, recall, f1, conf_matrix, roc_auc\n",
        "\n",
        "# Gaussian Naive Bayes\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"\\nGaussian Naive Bayes Model:\")\n",
        "gnb_accuracy, gnb_precision, gnb_recall, gnb_f1, gnb_conf_matrix, gnb_roc_auc = evaluate_model(gnb, X_test, y_test)\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "svm.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"\\nSupport Vector Machine Model:\")\n",
        "svm_accuracy, svm_precision, svm_recall, svm_f1, svm_conf_matrix, svm_roc_auc = evaluate_model(svm, X_test, y_test)\n",
        "\n",
        "# Random Forest\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"\\nRandom Forest Model:\")\n",
        "rf_accuracy, rf_precision, rf_recall, rf_f1, rf_conf_matrix, rf_roc_auc = evaluate_model(rf, X_test, y_test)\n",
        "\n",
        "# Gradient Boosting\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"\\nGradient Boosting Model:\")\n",
        "gb_accuracy, gb_precision, gb_recall, gb_f1, gb_conf_matrix, gb_roc_auc = evaluate_model(gb, X_test, y_test)\n",
        "\n",
        "# Logistic Regression\n",
        "\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"\\nLogistic Regression Model:\")\n",
        "lr_accuracy, lr_precision, lr_recall, lr_f1, lr_conf_matrix, lr_roc_auc = evaluate_model(lr, X_test, y_test)\n",
        "\n",
        "# K-Nearest Neighbors (KNN)\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"\\nK-Nearest Neighbors Model:\")\n",
        "knn_accuracy, knn_precision, knn_recall, knn_f1, knn_conf_matrix, knn_roc_auc = evaluate_model(knn, X_test, y_test)\n",
        "\n",
        "# Neural Network (MLPClassifier)\n",
        "\n",
        "mlp = MLPClassifier(random_state=42, max_iter=300)\n",
        "mlp.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"\\nNeural Network (MLPClassifier) Model:\")\n",
        "mlp_accuracy, mlp_precision, mlp_recall, mlp_f1, mlp_conf_matrix, mlp_roc_auc = evaluate_model(mlp, X_test, y_test)\n",
        "\n",
        "# Hyperparameter Tuning using GridSearchCV\n",
        "\n",
        "# Random Forest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'min_samples_split': [2, 4, 8],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search_rf = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                           param_grid=param_grid_rf,\n",
        "                           cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "                           scoring='accuracy',\n",
        "                           n_jobs=-1)\n",
        "\n",
        "grid_search_rf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"\\nBest parameters for Random Forest:\", grid_search_rf.best_params_)\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "print(\"\\nTuned Random Forest Model:\")\n",
        "best_rf_accuracy, best_rf_precision, best_rf_recall, best_rf_f1, best_rf_conf_matrix, best_rf_roc_auc = evaluate_model(best_rf_model, X_test, y_test)\n",
        "\n",
        "# Gradient Boosting\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'min_samples_split': [2, 4],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "grid_search_gb = GridSearchCV(estimator=GradientBoostingClassifier(random_state=42),\n",
        "                           param_grid=param_grid_gb,\n",
        "                           cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "                           scoring='accuracy',\n",
        "                           n_jobs=-1)\n",
        "\n",
        "grid_search_gb.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"\\nBest parameters for Gradient Boosting:\", grid_search_gb.best_params_)\n",
        "best_gb_model = grid_search_gb.best_estimator_\n",
        "\n",
        "print(\"\\nTuned Gradient Boosting Model:\")\n",
        "best_gb_accuracy, best_gb_precision, best_gb_recall, best_gb_f1, best_gb_conf_matrix, best_gb_roc_auc = evaluate_model(best_gb_model, X_test, y_test)\n",
        "\n",
        "# Logistic Regression\n",
        "param_grid_lr = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid_search_lr = GridSearchCV(estimator=LogisticRegression(random_state=42),\n",
        "                           param_grid=param_grid_lr,\n",
        "                           cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "                           scoring='accuracy',\n",
        "                           n_jobs=-1)\n",
        "\n",
        "grid_search_lr.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"\\nBest parameters for Logistic Regression:\", grid_search_lr.best_params_)\n",
        "best_lr_model = grid_search_lr.best_estimator_\n",
        "\n",
        "print(\"\\nTuned Logistic Regression Model:\")\n",
        "best_lr_accuracy, best_lr_precision, best_lr_recall, best_lr_f1, best_lr_conf_matrix, best_lr_roc_auc = evaluate_model(best_lr_model, X_test, y_test)\n",
        "\n",
        "# Ensemble Modeling - VotingClassifier\n",
        "# Create an ensemble of the best models (tuned)\n",
        "voting_clf = VotingClassifier(estimators=[('rf', best_rf_model), ('gb', best_gb_model), ('lr', best_lr_model)], voting='soft')\n",
        "voting_clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"\\nEnsemble Model (VotingClassifier):\")\n",
        "ensemble_accuracy, ensemble_precision, ensemble_recall, ensemble_f1, ensemble_conf_matrix, ensemble_roc_auc = evaluate_model(voting_clf, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5-UDDq8dnjvY"
      },
      "id": "5-UDDq8dnjvY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}